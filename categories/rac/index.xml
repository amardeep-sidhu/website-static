<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>RAC on amardeepsidhu.com</title><link>https://v2.amardeepsidhu.com/categories/rac/</link><description>Recent content in RAC on amardeepsidhu.com</description><generator>Hugo -- 0.145.0</generator><language>en</language><lastBuildDate>Wed, 10 Mar 2021 18:17:34 +0530</lastBuildDate><atom:link href="https://v2.amardeepsidhu.com/categories/rac/index.xml" rel="self" type="application/rss+xml"/><item><title>[FATAL] [INS-44000] Passwordless SSH connectivity is not setup</title><link>https://v2.amardeepsidhu.com/blog/2021/03/10/fatal-ins-44000-passwordless-ssh-connectivity-is-not-setup/</link><pubDate>Wed, 10 Mar 2021 18:17:34 +0530</pubDate><guid>https://v2.amardeepsidhu.com/blog/2021/03/10/fatal-ins-44000-passwordless-ssh-connectivity-is-not-setup/</guid><description>&lt;p>Faced this while running installer for setting up a 2 node RAC setup (version 19.8) on an Oracle SuperCluster. The error reported in the log is:&lt;/p>
&lt;pre tabindex="0">&lt;code>[FATAL] [INS-44000] Passwordless SSH connectivity is not setup from the local node node1 to the following nodes:
[node2]
[INS-06006] Passwordless SSH connectivity not set up between the following node(s): [node2]
&lt;/code>&lt;/pre>&lt;p>From the error it appears that the ssh is not setup between two nodes but actually that is not the case. Here the error message is bit misleading. It turned out to be an issue with scp with openssh version 8.x. Running the setup with -debug option gives the clue:&lt;/p></description></item><item><title>PRVF-4657 : Name resolution setup check for “db-scan” (IP address: x.x.x.101) failed</title><link>https://v2.amardeepsidhu.com/blog/2020/09/25/prvf-4657-name-resolution-setup-check-for-db-scan-ip-address-x-x-x-101-failed/</link><pubDate>Fri, 25 Sep 2020 19:41:28 +0530</pubDate><guid>https://v2.amardeepsidhu.com/blog/2020/09/25/prvf-4657-name-resolution-setup-check-for-db-scan-ip-address-x-x-x-101-failed/</guid><description>&lt;p>A quick note about an error I faced while running root.sh on an Exadata machine. The configuration tools failed with the following error:&lt;/p>
&lt;pre tabindex="0">&lt;code>Error is PRVF-4657 : Name resolution setup check for &amp;#34;db-scan&amp;#34; (IP address: x.x.x.101) failed
&lt;/code>&lt;/pre>&lt;p>I did nslookup on the scan name and it all seemed good. So why the error ? After spending another 5 minutes, I looked at /etc/hosts and there was it. Someone had populated /etc/hosts of DB nodes with all the hostnames entries including the scan name. Something like:&lt;/p></description></item><item><title>root.sh fails with CRS-2101:The OLR was formatted using version 3</title><link>https://v2.amardeepsidhu.com/blog/2017/11/18/root-sh-fails-with-crs-2101-the-olr-was-formatted-using-version-3/</link><pubDate>Sat, 18 Nov 2017 16:03:33 +0530</pubDate><guid>https://v2.amardeepsidhu.com/blog/2017/11/18/root-sh-fails-with-crs-2101-the-olr-was-formatted-using-version-3/</guid><description>&lt;p>Got this while trying to install 11.2.0.4 RAC on Redhat Linux 7.2. root.sh fails with a message like&lt;/p>
&lt;p>[sql]ohasd failed to start
Failed to start the Clusterware. Last 20 lines of the alert log follow:
2017-11-09 15:43:37.883:
[client(37246)]CRS-2101:The OLR was formatted using version 3.[/sql]&lt;/p>
&lt;p>This is bug 18370031. Need to apply the patch before running root.sh.&lt;/p></description></item><item><title>Failed to create voting files on disk group RECOC1</title><link>https://v2.amardeepsidhu.com/blog/2017/04/28/failed-to-create-voting-files-on-disk-group-recoc1/</link><pubDate>Fri, 28 Apr 2017 14:31:20 +0530</pubDate><guid>https://v2.amardeepsidhu.com/blog/2017/04/28/failed-to-create-voting-files-on-disk-group-recoc1/</guid><description>&lt;p>Long story short, faced this issue while running OneCommand for one Exadata system. The root.sh step (Initialize Cluster Software) was failing with the following error on the screen&lt;/p>
&lt;p>Checking file root_dm01dbadm02.in.oracle.com_2017-04-27_18-13-27.log on node dm01dbadm02.somedomain.com
Error: Error running root scripts, please investigate&amp;hellip;
Collecting diagnostics&amp;hellip;
Errors occurred. Send /u01/onecommand/linux-x64/WorkDir/Diag-170427_181710.zip to Oracle to receive assistance.&lt;/p>
&lt;p>Doesn’t make much sense. So let us check the log file of this step&lt;/p>
&lt;p>2017-04-27 18:17:10,463 [INFO][  OCMDThread][        ClusterUtils:413] Checking file root_dm01dbadm02.somedomain.com_2017-04-27_18-13-27.log on node inx321dbadm02.somedomain.com
2017-04-27 18:17:10,464 [INFO][  OCMDThread][        OcmdException:62] Error: Error running root scripts, please investigate&amp;hellip;
2017-04-27 18:17:10,464 [FINE][  OCMDThread][        OcmdException:63] Throwing OcmdException&amp;hellip; message:Error running root scripts, please investigate&amp;hellip;&lt;/p></description></item><item><title>Oracle RAC 12.1 – lsnodes exited with code 9</title><link>https://v2.amardeepsidhu.com/blog/2017/03/28/oracle-rac-12-1-lsnodes-exited-with-code-9/</link><pubDate>Tue, 28 Mar 2017 22:01:35 +0530</pubDate><guid>https://v2.amardeepsidhu.com/blog/2017/03/28/oracle-rac-12-1-lsnodes-exited-with-code-9/</guid><description>&lt;p>I was trying to do a 2 node RAC setup on Solaris 11.3 where Oracle Solaris Cluster 4.3 was already configured. Installed was running but the Cluster Node Information screen was appearing like this&lt;/p>
&lt;p>&lt;a href="https://v2.amardeepsidhu.com/blog/wp-content/uploads/2017/03/error.jpg">&lt;img alt="error" loading="lazy" src="https://v2.amardeepsidhu.com/blog/wp-content/uploads/2017/03/error_thumb.jpg">&lt;/a>&lt;/p>
&lt;p>The install log shows this:&lt;/p>
&lt;p>INFO: Checking cluster configuration details&lt;/p>
&lt;p>&lt;strong>INFO: Found Vendor Clusterware. Fetching Cluster Configuration&lt;/strong>&lt;/p>
&lt;p>&lt;strong>INFO: Executing [/tmp/OraInstall2017-03-28_12-50-48PM/ext/bin/lsnodes]&lt;/strong>&lt;/p>
&lt;p>with environment variables {TERM=xterm, LC_COLLATE=, SHLVL=3, JAVA_HOME=, XFILESEARCHPATH=/usr/dt/app-defaults/%L/Dt, SSH_CLIENT=172.16.64.55 56370 22, LC_NUMERIC=, LC_MESSAGES=, MAIL=/var/mail/oracle, PWD=/export/software/grid/grid, XTERM_VERSION=XTerm(320), WINDOWID=2097165, LOGNAME=oracle, _=*50727*/export/software/grid/grid/install/.oui, NLSPATH=/usr/dt/lib/nls/msg/%L/%N.cat, SSH_CONNECTION=172.16.64.55 56370 172.16.72.18 22, OLDPWD=/export/oracle, LC_CTYPE=, CLASSPATH=, PATH=/usr/bin:/usr/ccs/bin:/usr/bin:/bin:/export/software/grid/grid/install, LC_ALL=, DISPLAY=localhost:10.0, LC_MONETARY=, USER=oracle, HOME=/export/oracle, XTERM_SHELL=/bin/bash, XAUTHORITY=/tmp/ssh-xauth-mlq21a/xauthfile, A__z=&amp;quot;*SHLVL, XTERM_LOCALE=en_US.UTF-8, TZ=localtime, LC_TIME=, LANG=en_US.UTF-8}&lt;/p></description></item><item><title>addNode.sh, failed root.sh and IB listener</title><link>https://v2.amardeepsidhu.com/blog/2016/09/13/addnode-sh-failed-root-sh-and-ib-listener/</link><pubDate>Tue, 13 Sep 2016 19:44:56 +0530</pubDate><guid>https://v2.amardeepsidhu.com/blog/2016/09/13/addnode-sh-failed-root-sh-and-ib-listener/</guid><description>&lt;p>So this customer has an Exadata quarter rack and they have an IB listener configured on both DB nodes (for DB connections from a multi-racked Exalogic system). We were adding a new DB node to this rack. So just followed the standard procedure of creating users, directories etc on the new node, setting up ssh equivalence and running addNode.sh. All went fine but root.sh failed. Little looking into the logs revealed that it failed while running &lt;strong>srvctl start listener –n &amp;lt;node_name&amp;gt;&lt;/strong>&lt;/p></description></item></channel></rss>