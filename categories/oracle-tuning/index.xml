<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Oracle Tuning on amardeepsidhu.com</title><link>https://v2.amardeepsidhu.com/categories/oracle-tuning/</link><description>Recent content in Oracle Tuning on amardeepsidhu.com</description><generator>Hugo -- 0.145.0</generator><language>en</language><lastBuildDate>Mon, 22 Mar 2021 12:54:19 +0530</lastBuildDate><atom:link href="https://v2.amardeepsidhu.com/categories/oracle-tuning/index.xml" rel="self" type="application/rss+xml"/><item><title>Database performance degradation due to multipath issues</title><link>https://v2.amardeepsidhu.com/blog/2021/03/22/database-performance-degradation-due-to-multipath-issues/</link><pubDate>Mon, 22 Mar 2021 12:54:19 +0530</pubDate><guid>https://v2.amardeepsidhu.com/blog/2021/03/22/database-performance-degradation-due-to-multipath-issues/</guid><description>&lt;p>To put it in bit of an Indian context, database is not your daughter-in-law that you can blame it for every performance issue that occurs in the environment. But it does happen. Most of the time it is the database that is blamed for all such issues. Many times, the issues are in some other layer like OS, network or storage.&lt;/p>
&lt;p>Faced this issue recently at one of the customer sites where performance in one of the databases went down suddenly. It was a 2 node RAC on 12.1.0.2 running on Linux 7 using some kind of Hitachi SSD storage array. There were no changes as per DBA, application, OS and storage teams. But something must have changed somewhere. Otherwise why would performance degrade just like that. I &amp;amp; my colleague checked some details and found that something happened in the morning a day before. Starting from that point in time, the execution time for all the commonly run queries shot up. Generally speaking, when all the queries are doing bad and you are sure that nothing has been changed on the database side, the reasons could be outside the database. But being a DBA, it is not easy to prove that. We took AWRs from good and bad times and the wait events section looked like this:&lt;/p></description></item><item><title>dbc_min_pct and dbc_max_pct in HP-UX</title><link>https://v2.amardeepsidhu.com/blog/2011/05/25/dbc_min_pct-and-dbc_max_pct-in-hp-ux/</link><pubDate>Wed, 25 May 2011 16:45:56 +0530</pubDate><guid>https://v2.amardeepsidhu.com/blog/2011/05/25/dbc_min_pct-and-dbc_max_pct-in-hp-ux/</guid><description>&lt;p>It was a 10g (10.2.0.5 on HP-UX 11.23 RISC) database which was recently upgraded from 9.2.0.8. The CPU and memory utilization was going really high. After tuning few of the queries coming in top, CPU usage was coming within accetable limits but the memory usage was still high. There was a total of 16 GB of RAM on the server and the usage was above 90%, constantly. One of the reasons behind high usage was increase in the SGA size. It was increased from 2.5 GB (in 9i) to around 5 GB (in 10g). Another major chunk was being eaten by OS buffer cache. While looking at the memory usage with kmeminfo:[bash]Buffer cache        =  1048448    4.0g  25%  details with -bufcache[/bash]&lt;/p></description></item></channel></rss>