<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Exadata on amardeepsidhu.com</title><link>https://amardeepsidhu.com/categories/exadata/</link><description>Recent content in Exadata on amardeepsidhu.com</description><generator>Hugo -- 0.147.9</generator><language>en</language><lastBuildDate>Mon, 09 May 2022 13:26:00 +0530</lastBuildDate><atom:link href="https://amardeepsidhu.com/categories/exadata/index.xml" rel="self" type="application/rss+xml"/><item><title>Adding a new cell to Exadata with asm scoped security enabled</title><link>https://amardeepsidhu.com/blog/2022/05/09/adding-a-new-cell-to-exadata-with-asm-scoped-security-enabled/</link><pubDate>Mon, 09 May 2022 13:26:00 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2022/05/09/adding-a-new-cell-to-exadata-with-asm-scoped-security-enabled/</guid><description>&lt;p>A customer is using an Exadata X8M-2 machine with multiple VMs (hence multiple clusters). I was working on adding a new storage cell to the configuration. After creating griddisks on the new cell and updating cellip.ora on all the VMs, I noticed that none of the clusters was able to see the new griddisks. I checked the usual suspects like if asm_diskstring was set properly, private network subnet mask on new cell was same as the old ones. All looked good. I started searching about the issue and stumbled upon some references mentioning &lt;a href="https://mudasirhakakblog.wordpress.com/2019/03/01/asm-scoped-security/">ASM scoped security&lt;/a>. I checked on one of the existing cells and that actually was the issue. The existing nodes had it enabled while the new one hadn&amp;rsquo;t. Running this command on an existing cell&lt;/p></description></item><item><title>Smokescreen detects traffic from an Exadata VM</title><link>https://amardeepsidhu.com/blog/2022/03/21/smokescreen-detects-traffic-from-an-exadata-vm/</link><pubDate>Mon, 21 Mar 2022 19:30:16 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2022/03/21/smokescreen-detects-traffic-from-an-exadata-vm/</guid><description>&lt;p>A customer who is using an Exadata X8M-2 with multiple VMs had Smokescreen deployed in their company recently and they reported an issue that one of the Smokescreen decoy servers in their DC was seeing traffic from one of the Exadata VMs on a certain port. That was rather confusing as that port was the database listener port on that VM and why would a VM with Oracle RAC deployed try to access any random IP on the listener port. Also it was happening only for this VM. Nothing for so many other VMs.&lt;/p></description></item><item><title>File system already present at specified mount point /dbfs_direct</title><link>https://amardeepsidhu.com/blog/2021/06/05/file-system-already-present-at-specified-mount-point-dbfs_direct/</link><pubDate>Sat, 05 Jun 2021 20:19:37 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2021/06/05/file-system-already-present-at-specified-mount-point-dbfs_direct/</guid><description>&lt;p>It was actually funny. So thought about posting it that sometimes how we can miss the absolute basics. This customer is using a virtualized Exadata with multiple VMs. One VM hosts the database meant to be used for dbfs and another VM connects to this DB over IB to mount dbfs file system using dbfs_client. One day VMs were rebooted and due to some reason the dbfs filesystem didn&amp;rsquo;t mount on startup. It went on for few days and they couldn&amp;rsquo;t mount it. One day I got a chance to look at it and the error they were facing was:&lt;/p></description></item><item><title>Doing an Exadata mixed cells config with OEDA</title><link>https://amardeepsidhu.com/blog/2020/10/27/doing-an-exadata-mixed-cells-config-with-oeda/</link><pubDate>Tue, 27 Oct 2020 18:53:37 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2020/10/27/doing-an-exadata-mixed-cells-config-with-oeda/</guid><description>&lt;p>Earlier versions of OEDA didn&amp;rsquo;t allow you to have mixed cells in the configuration i.e. High Capacity (HC) and Extreme Flash (EF). The way to deal with that configuration was that deploy the system with either HC or EF cells and then manually configure the remaining cells.&lt;/p>
&lt;p>I am not sure when did it change but the newer versions allow you have mixed type of cells in a single OEDA configuration. Once you select the hardware, there is an additional option called &lt;strong>Enable Additional Storage&lt;/strong>, where you can select the other type of cells. The minimum number of cells has to be three to use this option. Also the cells that are at the bottom of the rack physically should be selected as main storage and the other cells should be added as additional storage as that is how OEDA builds the configuration files.&lt;/p></description></item><item><title>PRVF-4657 : Name resolution setup check for “db-scan” (IP address: x.x.x.101) failed</title><link>https://amardeepsidhu.com/blog/2020/09/25/prvf-4657-name-resolution-setup-check-for-db-scan-ip-address-x-x-x-101-failed/</link><pubDate>Fri, 25 Sep 2020 19:41:28 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2020/09/25/prvf-4657-name-resolution-setup-check-for-db-scan-ip-address-x-x-x-101-failed/</guid><description>&lt;p>A quick note about an error I faced while running root.sh on an Exadata machine. The configuration tools failed with the following error:&lt;/p>
&lt;pre tabindex="0">&lt;code>Error is PRVF-4657 : Name resolution setup check for &amp;#34;db-scan&amp;#34; (IP address: x.x.x.101) failed
&lt;/code>&lt;/pre>&lt;p>I did nslookup on the scan name and it all seemed good. So why the error ? After spending another 5 minutes, I looked at /etc/hosts and there was it. Someone had populated /etc/hosts of DB nodes with all the hostnames entries including the scan name. Something like:&lt;/p></description></item><item><title>Using Secure Fabric for network isolation in KVM environments on Exadata</title><link>https://amardeepsidhu.com/blog/2020/07/17/using-secure-fabric-for-network-isolation-in-kvm-environments-on-exadata/</link><pubDate>Fri, 17 Jul 2020 21:21:03 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2020/07/17/using-secure-fabric-for-network-isolation-in-kvm-environments-on-exadata/</guid><description>&lt;p>Exadata storage software version 20.1 introduces a new feature called &amp;ldquo;Secure Fabric&amp;rdquo; for KVM based multi cluster deployments (Exadata X8M). It enables network isolation between multiple tenants (i.e. KVM VMs based RAC clusters). This feature aligns with Infiniband Partitioning on OVM based systems. There are customers who in such scenarios want that VMs of one RAC shouldn&amp;rsquo;t be able to see traffic of the other RAC VMs. This feature achieves that. Similar to Pkeys in IB switches, here it uses a double VLAN tagging system where the first tag identiefies the network partition and the second tag is used to denote membership level of the VM. &lt;a href="https://docs.oracle.com/en/engineered-systems/exadata-database-machine/dbmin/exadata-network-requirements.html#GUID-75CC8740-CC7F-4A7B-B69B-B93E927E80EC">Exadata documention&lt;/a> has more details.&lt;/p></description></item><item><title>Exadata Virtualized DB node restore</title><link>https://amardeepsidhu.com/blog/2020/05/11/exadata-virtualized-db-node-restore/</link><pubDate>Mon, 11 May 2020 21:31:43 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2020/05/11/exadata-virtualized-db-node-restore/</guid><description>&lt;p>There are two common scenarios when we may need this:&lt;/p>
&lt;ul>
&lt;li>An existing DB node has crashed and is unrecoverable (due to some failure and non-availability of any backups. Though some of the things may need to be done even if the backups were available).&lt;/li>
&lt;li>We have an existing Exadata rack that is virtualized. Now there is a new DB node and the existing clusters need to be extended to include the VMs on this new node.&lt;/li>
&lt;/ul>
&lt;p>I recently faced the first scenario where a virtualized DB node crashed and wasn&amp;rsquo;t recoverable. A bare metal DB node restore is a relatively simple procedure where we just have to reimage the node, create the needed directories, users etc and add it to the RAC cluster. In case of virtualization, the creation of VMs is an additional step that needs to be done. That makes it slightly more complex.&lt;/p></description></item><item><title>dbnodeupdate.sh appears to be stuck</title><link>https://amardeepsidhu.com/blog/2019/12/21/dbnodeupdate-sh-appears-to-be-stuck/</link><pubDate>Sat, 21 Dec 2019 06:37:33 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2019/12/21/dbnodeupdate-sh-appears-to-be-stuck/</guid><description>&lt;p>I was patching an Exadata db node from 18.1.5.0.0.180506 to 19.3.2.0.0.191119. It had been more than an hour and dbnodeupdate.sh appeared to be stuck. Trying to ssh to the node was giving &amp;ldquo;connection refused&amp;rdquo; and the console had this output (some output removed for brevity):&lt;/p>
&lt;pre tabindex="0">&lt;code>[ 458.006444] upgrade[8876]: [642/676] (72%) installing exadata-sun-computenode-19.3.2.0.0.191119-1...
&amp;lt;&amp;gt;
[ 459.991449] upgrade[8876]: Created symlink /etc/systemd/system/multi-user.target.wants/exadata-iscsi-reconcile.service, pointing to /etc/systemd/system/exadata-iscsi-reconcile.service.
[ 460.011466] upgrade[8876]: Looking for unit files in (higher priority first):
[ 460.021436] upgrade[8876]: /etc/systemd/system
[ 460.028479] upgrade[8876]: /run/systemd/system
[ 460.035431] upgrade[8876]: /usr/local/lib/systemd/system
[ 460.042429] upgrade[8876]: /usr/lib/systemd/system
[ 460.049457] upgrade[8876]: Looking for SysV init scripts in:
[ 460.057474] upgrade[8876]: /etc/rc.d/init.d
[ 460.064430] upgrade[8876]: Looking for SysV rcN.d links in:
[ 460.071445] upgrade[8876]: /etc/rc.d
[ 460.076454] upgrade[8876]: Looking for unit files in (higher priority first):
[ 460.086461] upgrade[8876]: /etc/systemd/system
[ 460.093435] upgrade[8876]: /run/systemd/system
[ 460.100433] upgrade[8876]: /usr/local/lib/systemd/system
[ 460.107474] upgrade[8876]: /usr/lib/systemd/system
[ 460.114432] upgrade[8876]: Looking for SysV init scripts in:
[ 460.122455] upgrade[8876]: /etc/rc.d/init.d
[ 460.129458] upgrade[8876]: Looking for SysV rcN.d links in:
[ 460.136468] upgrade[8876]: /etc/rc.d
[ 460.141451] upgrade[8876]: Created symlink /etc/systemd/system/multi-user.target.wants/exadata-multipathmon.service, pointing to /etc/systemd/system/exadata-multipathmon.service.
&lt;/code>&lt;/pre>&lt;p>There was not much that I could do so just waited. Also created an SR with Oracle Support and they also suggested to wait. It started moving after some time and completed successfully. Finally when the node came up, i checked that there was an NFS mount entry in /etc/rc.local and that was what created the problem. For the second node, we commented this out and it was all smooth. Important to comment out all NFS entries during patching to avoid all such issues. I had commented the ones in /etc/fstab but the one in rc.local was an unexpected one.&lt;/p></description></item><item><title>Understanding grid disks in Exadata</title><link>https://amardeepsidhu.com/blog/2019/02/18/understanding-grid-disks-in-exadata/</link><pubDate>Mon, 18 Feb 2019 18:37:25 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2019/02/18/understanding-grid-disks-in-exadata/</guid><description>&lt;p>Use of Exadata storage cells seems to be a very poorly understood concept. A lot of people have confusions about how exactly ASM makes uses of disks from storage cells. Many folks assume there is some sort of RAID configured in the storage layer whereas there is nothing like that. I will try to explain some of the concepts in this post.&lt;/p>
&lt;p>Let&amp;rsquo;s take an example of an Exadata quarter rack that has 2 db and 3 storage nodes (node means a server here). Few things to note:&lt;/p></description></item><item><title>dbca doesn’t list diskgroups</title><link>https://amardeepsidhu.com/blog/2018/12/26/dbca-doesnt-list-diskgroups/</link><pubDate>Wed, 26 Dec 2018 21:01:20 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2018/12/26/dbca-doesnt-list-diskgroups/</guid><description>&lt;p>This is an Exadata machine running GI version 18.3.0.0.180717 and DB version 12.1.0.2.180717. On one of the DB nodes while running dbca, it doesn&amp;rsquo;t list the diskgroups. it works fine on the other node.&lt;/p>
&lt;p>I cheked the dbca trace and found that the kfod command was failing. I tried to run it manually and got the same error:&lt;/p>
&lt;pre tabindex="0">&lt;code>[oracle@exadb01 ~]$ /u01/app/18.0.0.0/grid/bin/kfod op=groups verbose=true
KFOD-00300: OCI error [-1] [OCI error] [Could not fetch details] [-105777048]
KFOD-00105: Could not open pfile &amp;#39;init@.ora&amp;#39;
[oracle@exadb01 ~]$
&lt;/code>&lt;/pre>&lt;p>I ran it with strace then:&lt;/p></description></item><item><title>New web based OEDA for Exadata</title><link>https://amardeepsidhu.com/blog/2018/11/21/new-web-based-oeda-for-exadata/</link><pubDate>Wed, 21 Nov 2018 14:47:18 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2018/11/21/new-web-based-oeda-for-exadata/</guid><description>&lt;p>It started with an xls sheet (that was called dbm configurator) . Then OEDA (Oracle Exadata Deployment Assistant) was introduced that was a Java based GUI tool to enter all the information needed to configure an Exadata machine. Now with the latest patch released in Oct, OEDA has changed again; to become a web based tool. It is deployed on WebLogic and comes with some new features as well. SuperCluster deployments will continue to use the Java based OEDA tool.  The new interface has support for Exadata, ZDLRA and ExaCC. It is backward compatible and can import the XMLs generated by older versions of OEDA. Some of the new features include the ability to configure single instance homes, create more than 2 diskgroups, create more than 1 database homes and databases, allow ILOMs to have a different subnet etc.&lt;/p></description></item><item><title>ksplice kernel updates and Exadata patching</title><link>https://amardeepsidhu.com/blog/2017/11/05/ksplice-kernel-updates-and-exadata-patching/</link><pubDate>Sun, 05 Nov 2017 23:02:05 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2017/11/05/ksplice-kernel-updates-and-exadata-patching/</guid><description>&lt;p>If you have installed some one off ksplice fix for kernel on Exadata, remember to uninstall it before you do a kernel upgrade  eg regular Exadata patching. As such fixes are kernel version specific so they may not work with the newer version of the kernel.&lt;/p></description></item><item><title>Failed to create voting files on disk group RECOC1</title><link>https://amardeepsidhu.com/blog/2017/04/28/failed-to-create-voting-files-on-disk-group-recoc1/</link><pubDate>Fri, 28 Apr 2017 14:31:20 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2017/04/28/failed-to-create-voting-files-on-disk-group-recoc1/</guid><description>&lt;p>Long story short, faced this issue while running OneCommand for one Exadata system. The root.sh step (Initialize Cluster Software) was failing with the following error on the screen&lt;/p>
&lt;p>Checking file root_dm01dbadm02.in.oracle.com_2017-04-27_18-13-27.log on node dm01dbadm02.somedomain.com
Error: Error running root scripts, please investigate&amp;hellip;
Collecting diagnostics&amp;hellip;
Errors occurred. Send /u01/onecommand/linux-x64/WorkDir/Diag-170427_181710.zip to Oracle to receive assistance.&lt;/p>
&lt;p>Doesn’t make much sense. So let us check the log file of this step&lt;/p>
&lt;p>2017-04-27 18:17:10,463 [INFO][  OCMDThread][        ClusterUtils:413] Checking file root_dm01dbadm02.somedomain.com_2017-04-27_18-13-27.log on node inx321dbadm02.somedomain.com
2017-04-27 18:17:10,464 [INFO][  OCMDThread][        OcmdException:62] Error: Error running root scripts, please investigate&amp;hellip;
2017-04-27 18:17:10,464 [FINE][  OCMDThread][        OcmdException:63] Throwing OcmdException&amp;hellip; message:Error running root scripts, please investigate&amp;hellip;&lt;/p></description></item><item><title>OneCommand Step 1 error</title><link>https://amardeepsidhu.com/blog/2017/04/10/onecommand-step-1-error/</link><pubDate>Mon, 10 Apr 2017 22:20:41 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2017/04/10/onecommand-step-1-error/</guid><description>&lt;p>Hit this silly issue while doing an Exadata deployment for a customer. Step 1 was giving the following error:&lt;/p>
&lt;p>ERROR: 192.168.99.102 configured on dm01celadm01.example.com as dm01dbadm02 does not match expected value dm01dbadm02.example.com&lt;/p>
&lt;p>I wasn&amp;rsquo;t able to make sense of it for quite some time until a colleague pointed out that the reverse lookup entries should be done for FQDN only. As it is clear in the above message reverse lookup of the IP 192.168.99.102 returns dm01dbadm02 instead of dm01dbadm02.example.com. Fixing this in DNS resolved the issue.&lt;/p></description></item><item><title>addNode.sh, failed root.sh and IB listener</title><link>https://amardeepsidhu.com/blog/2016/09/13/addnode-sh-failed-root-sh-and-ib-listener/</link><pubDate>Tue, 13 Sep 2016 19:44:56 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2016/09/13/addnode-sh-failed-root-sh-and-ib-listener/</guid><description>&lt;p>So this customer has an Exadata quarter rack and they have an IB listener configured on both DB nodes (for DB connections from a multi-racked Exalogic system). We were adding a new DB node to this rack. So just followed the standard procedure of creating users, directories etc on the new node, setting up ssh equivalence and running addNode.sh. All went fine but root.sh failed. Little looking into the logs revealed that it failed while running &lt;strong>srvctl start listener –n &amp;lt;node_name&amp;gt;&lt;/strong>&lt;/p></description></item><item><title>OEDA&amp;ndash;Things to keep an eye on</title><link>https://amardeepsidhu.com/blog/2016/09/08/oeda-things-to-keep-an-eye-on/</link><pubDate>Thu, 08 Sep 2016 15:44:15 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2016/09/08/oeda-things-to-keep-an-eye-on/</guid><description>&lt;p>So if you are filling an &lt;strong>OEDA&lt;/strong> for Exadata deployment there are few things you should take care of. Most of the screens are self explanatory but there are some bits where one should focus little more. I am running the Aug version of it and the screenshots below are from that version.&lt;/p>
&lt;ol>
&lt;li>
&lt;p>On the &lt;strong>Define customer networks&lt;/strong> screen, the client network is the actual network where your data is going to flow. So typically it is going to be bonded (for high availability) and depending upon the network in your data center you have to select one out of 1/10 G copper and 10 G optical.&lt;/p></description></item><item><title>ORA-56841: Master Diskmon cannot connect to a CELL</title><link>https://amardeepsidhu.com/blog/2016/05/19/ora-56841-master-diskmon-cannot-connect-to-a-cell/</link><pubDate>Thu, 19 May 2016 22:15:05 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2016/05/19/ora-56841-master-diskmon-cannot-connect-to-a-cell/</guid><description>&lt;p>Faced this error while querying v$asm_disk after adding new storage cell IPs to cellip.ora on DB nodes of an existing cluster on Exadata. Query ends with &lt;em>ORA-03113 end-of-file on communication channel&lt;/em> and &lt;em>ORA-56841&lt;/em> is reported in &lt;em>$ORA_CRS_HOME/log/&lt;!-- raw HTML omitted -->/diskmon/diskmon.log&lt;/em>. Reason in my case was that the new cell was using different subnet for IB. It was pingable from the db nodes but querying v$asm_disk wasn&amp;rsquo;t working. Changing the subnet for IB on new cell to the one on existing cells fixed the issue.&lt;/p></description></item><item><title>Want to learn Exadata ?</title><link>https://amardeepsidhu.com/blog/2015/01/02/want-to-learn-exadata/</link><pubDate>Fri, 02 Jan 2015 14:49:15 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2015/01/02/want-to-learn-exadata/</guid><description>&lt;p>Many people have asked me this question that how they can learn Exadata ? It starts sounding even more difficult as a lot of people don’t have access to Exadata environments. So thought about writing a small post on the same.&lt;/p>
&lt;p>It actually is not as difficult as it sounds. There are a lot of really good resources available from where you can learn about Exadata architecture and the things that work differently from any non-Exadata platform. You might be able to do lot more RnD if you have got access to an Exadata environment but don’t worry if you haven&amp;rsquo;t. Without that also there is a lot that you can explore. So here we go:&lt;/p></description></item><item><title>Updating to Exadata 11.2.3.1.1</title><link>https://amardeepsidhu.com/blog/2012/08/19/updating-to-exadata-11-2-3-1-1/</link><pubDate>Sun, 19 Aug 2012 22:37:41 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2012/08/19/updating-to-exadata-11-2-3-1-1/</guid><description>&lt;p>Just a quick note about change in the way the compute nodes are patched starting from version 11.2.3.1.1. For earlier versions Oracle provided the minimal pack for patching the compute nodes. Starting with version 11.2.3.1.1 Oracle has discontinued the minimal pack and the updates to compute nodes are done via Unbreakable Linux Network (ULN).&lt;/p>
&lt;p>Now there are three ways to update the compute nodes:&lt;/p>
&lt;ol>
&lt;li>
&lt;p>You have internet access on the Compute nodes. In this case you can download patch &lt;strong>13741363&lt;/strong>, complete the one time setup and start the update.&lt;/p></description></item><item><title>DML and HCC – Exadata</title><link>https://amardeepsidhu.com/blog/2011/12/22/dml-and-hcc-exadata/</link><pubDate>Thu, 22 Dec 2011 00:01:11 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2011/12/22/dml-and-hcc-exadata/</guid><description>&lt;p>Hybrid Columnar Compression (HCC) is a new awesome feature in Exadata that helps in saving a lot of storage space in your environment. &lt;a href="http://www.oracle.com/technetwork/middleware/bi-foundation/ehcc-twp-131254.pdf">This whitepaper&lt;/a> on Oracle website explains this feature in detail. Also Uwe Hesse has an excellent &lt;em>how to use all this&lt;/em> &lt;a href="http://uhesse.wordpress.com/2011/01/21/exadata-part-iii-compression/">post on his blog&lt;/a>. You can see the compression levels one can achive by making use of HCC. It is very simple to use feature but one needs to be aware of few things before using HCC extensively as otherwise all your storage calculations may go weird. Here are few of the things to keep in mind:&lt;/p></description></item></channel></rss>