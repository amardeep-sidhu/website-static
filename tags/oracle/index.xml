<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/"><channel><title>Oracle on amardeepsidhu.com</title><link>https://amardeepsidhu.com/tags/oracle/</link><description>Recent content in Oracle on amardeepsidhu.com</description><generator>Hugo -- 0.147.9</generator><language>en</language><lastBuildDate>Wed, 15 Oct 2025 19:34:12 +0530</lastBuildDate><atom:link href="https://amardeepsidhu.com/tags/oracle/index.xml" rel="self" type="application/rss+xml"/><item><title>Importance of getting the basics right #JoelKallmanDay</title><link>https://amardeepsidhu.com/blog/2025/10/importance-of-getting-the-basics-right-joelkallmanday/</link><pubDate>Wed, 15 Oct 2025 19:34:12 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2025/10/importance-of-getting-the-basics-right-joelkallmanday/</guid><description>&lt;p>This is my submission for JoelKallmanDay, a community day planned by &lt;a href="https://oracle-base.com/blog/">Tim&lt;/a> every year on &lt;a href="https://oracle-base.com/blog/2025/09/24/joel-kallman-day-2025-announcement/">October 15th&lt;/a> as a tribute to &lt;a href="https://joelkallman.blogspot.com/">Joel Kallman&lt;/a>.&lt;/p>
&lt;p>It is an old story that I am sharing. There was a customer that was using a Loan Management application and the back end was an Oracle database (a single instance, if I remember correctly). The hardware they were using was nearing EOL and they got an Exadata and moved the database there. They had high expectations and were expecting the application to be blazingly fast; it was a brand new Exadata, after all. But the experience was rather disappointing. There were application hangs, slowness and user complaints. When we (as a team) looked at the AWS/ASH reports from the system, there were things that needed immediate fixes. There were queries doing full tables scans and returning only a few rows. Then there were sequences where the cache size was set to zero. It appeared that the application was never tested with a RAC database. Creating the missing indexes and adjusting the cache sizes of the frequently used sequences appeared to be a low hanging fruit and it actually was. Fixing these two things gave a reasonable amount of relief. Of course, there was more that needed to be done to bring things on the track.&lt;/p></description></item><item><title>SQL Performance - Tune It or Buy It ?</title><link>https://amardeepsidhu.com/blog/2025/07/sql-performance-tune-it-or-buy-it/</link><pubDate>Mon, 28 Jul 2025 08:50:12 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2025/07/sql-performance-tune-it-or-buy-it/</guid><description>&lt;p>I was thinking about this while sitting in &lt;a href="https://viveklsharma.wordpress.com/">Vivek&lt;/a>&amp;rsquo;s session at &lt;a href="https://www.aioug.org/ocyatra/2025">OCYatra&lt;/a> in Gurgaon. He was talking about the techniques one can use to optimize badly performing SQLs. But there does exist the other side of this story i.e. throwing hardware at a performance problem to fix it. Of course, it works till a point only and it can&amp;rsquo;t solve every damn performance problem out there. But it is relatively easier to do (costs money, though) and depending upon where you are hosting your workloads, can be quicker too. You see CPU usage going up or users complaining, simple thing to do is to throw more cores at the database. If the system is CPU starved, it is going to give some temporary relief and you can control the situation. Same can be the case with the storage IOPS. In some extreme cases, you could even migrate the database to a more powerful hardware. With systems like Exadata being around which can make even a bad SQL do fairly well, this lever becomes even more powerful. But is it sustainable or is it the right way to deal with these kind of issues?&lt;/p></description></item><item><title>Decoding OCI's Database Deployment Options - Part 2</title><link>https://amardeepsidhu.com/blog/2025/07/decoding-ocis-database-deployment-options-part2/</link><pubDate>Sun, 20 Jul 2025 19:03:12 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2025/07/decoding-ocis-database-deployment-options-part2/</guid><description>&lt;p>In &lt;a href="https://amardeepsidhu.com/blog/2025/06/decoding-ocis-database-deployment-options-part1/">part1&lt;/a>, I summarized the options available for DB deployment on OCI and described the Base Database Service. In this post I will talk about the second group i.e. Exadata platform based services in detail and explore the possible deployment scenarios. When it comes to Exadata based options, it get a little complex as there are multiple ways to do it. To reiterate, there are two ways the deployment can be done. One is in the public cloud and another one is the private cloud (Exadata Cloud@Customer aka ExaCC) where the hardware is deployed in the customer&amp;rsquo;s data center. Let&amp;rsquo;s now explore the different offerings.&lt;/p></description></item><item><title>Decoding OCI's Database Deployment Options - Part 1</title><link>https://amardeepsidhu.com/blog/2025/06/decoding-ocis-database-deployment-options-part1/</link><pubDate>Sun, 29 Jun 2025 17:25:12 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2025/06/decoding-ocis-database-deployment-options-part1/</guid><description>&lt;p>So, you are looking to run a database on Oracle Cloud Infrastructure (OCI), right ? Great ! But then you login, and suddenly you are faced with a whole range of services that can feel a bit&amp;hellip;overwhelming. It&amp;rsquo;s not always obvious which one&amp;rsquo;s the right fit, especially for someone new to the OCI database landscape. That&amp;rsquo;s why I wanted to start this series of posts where we will walk through all the options that OCI throws at us for deploying databases.&lt;/p></description></item><item><title>Can’t su to oracle user</title><link>https://amardeepsidhu.com/blog/2023/01/cant-su-to-oracle-user/</link><pubDate>Fri, 20 Jan 2023 16:55:50 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2023/01/cant-su-to-oracle-user/</guid><description>&lt;p>Last week, got this issue reported by a DBA that he wasn&amp;rsquo;t able to su to oracle user from root on a Oracle Base Database VM in OCI. The login of opc user worked fine and he could do sudo su to root but he couldn&amp;rsquo;t su to oracle. When he did it just came back to root shell.&lt;/p>
&lt;pre tabindex="0">&lt;code>[root@xxx ~]# su - oracle
Last login: Fri Jan 12 10:20:38 UTC 2023
[root@xxx ~]#
&lt;/code>&lt;/pre>&lt;p>There was nothing relevant in /var/log/messages or /var/log/secure. I tried it for some other user and it worked fine. Then I suspected something with the profile of oracle user and voila ! The .bashrc looked like this&lt;/p></description></item><item><title>Implementing ZDLRA – Part 2</title><link>https://amardeepsidhu.com/blog/2020/10/implementing-zdlra-part-2/</link><pubDate>Tue, 06 Oct 2020 18:06:53 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2020/10/implementing-zdlra-part-2/</guid><description>&lt;p>In &lt;a href="https://amardeepsidhu.com/blog/2020/09/09/implementing-zdlra-part-1/">part 1&lt;/a>, we discussed few things that you should take care before implementation of a ZDLRA. In this post, we will discuss few more things that you should review before or at the time of implementation:&lt;/p>
&lt;ol>
&lt;li>If you are getting two ZDLRAs (one each for primary and standby sites), there are two ways they can be deployed. One scenario is where all the primary databases (or the database that have no standby) backup to RA at the primary site and then the data is replicated from primary RA to RA at the standby site. This works well for the DBs that have no standby database. For the DBs where there is a standby database, there is a better architecture that can be deployed. In that scenario, primary databases backup to primary RA and the standby databases backup to standby RA. That saves you all the traffic over replication network. Oracle has published a whitepaper on how to do this configuration. Few of the instructions in this paper are a bit dated but it gives a good overall idea of how to do the implementation.&lt;/li>
&lt;li>Keep an eye on the features supported for different DB versions. An interesting one is that real-time redo shipping from standby databases is supported on 12c+ databases only. It is not supported for 11g. There could be other similar things. MOS note 1995866.1 has these details.&lt;/li>
&lt;li>Depending upon the ZDLRA software version being deployed, it may need a minimum version of EM and the ZDLRA plugin. MOS note 2542836.1 has these details.&lt;/li>
&lt;li>Make sure after discovering the the primary and standby databases in EM, their primary-standby relationship is reflected.&lt;/li>
&lt;li>Real-time redo sent to ZDLRA is compressed but the archive logs backup will be compressed only if you use compression in the RMAN command. It is always good to include backup archivelog command with daily incremental job to make sure that no archive log is missed.&lt;/li>
&lt;li>Many of the environments have separate networks for backup traffic. Make sure the backup traffic to ZDLRA uses DB server&amp;rsquo;s backup network. If that is not the case, you may need to add an explicit route on DB server for ZDLRA client/VIP/scan IPs.&lt;/li>
&lt;li>There are going to be different users that you will need to use: one OS user for deploying the EM agent, one DB user that will be used to run the backups. Depending upon your environment, it may oracle OS user, SYS DB user or could be some other named user created for this purpose.&lt;/li>
&lt;/ol>
&lt;p>In next few posts, we will discuss some of the issues I have faced while doing ZDLRA implementation for some customers.&lt;/p></description></item><item><title>Implementing ZDLRA – Part 1</title><link>https://amardeepsidhu.com/blog/2020/09/implementing-zdlra-part-1/</link><pubDate>Wed, 09 Sep 2020 18:33:39 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2020/09/implementing-zdlra-part-1/</guid><description>&lt;p>Zero Data Loss Recovery Appliance (ZDLRA) is Oracle&amp;rsquo;s solution for database backups. It has many advantages over other backup solutions that are available in the market. &lt;a href="https://blogs.oracle.com/frankwickham/zero-data-loss-recovery-appliance-zdlra">This post&lt;/a> has a brief introduction to ZDLRA and few links for further reading. This is a quick post about few of things that you should keep in mind if you are planning to get a ZDLRA (RA in short). Of course, there is a lot more that is needed while executing the whole plan, but these are some of the basics:&lt;/p></description></item><item><title>OGB Appreciation Day : Thank you community ! (#ThanksOGB)</title><link>https://amardeepsidhu.com/blog/2019/10/ogb-appreciation-day-thank-you-community-thanksogb/</link><pubDate>Thu, 10 Oct 2019 19:40:04 +0530</pubDate><guid>https://amardeepsidhu.com/blog/2019/10/ogb-appreciation-day-thank-you-community-thanksogb/</guid><description>&lt;p>It was &lt;a href="https://oracle-base.com/blog/2019/09/30/ogb-appreciation-day-2019-thanksogb/">started by Tim Hall&lt;/a> in 2016. This is a Thank you community post. There are so many experts posting on Oracle related forums, doing blog posts, sharing their scripts with everyone. All of you are doing a great job. I would like to mention three names especially:&lt;/p>
&lt;p>&lt;a href="https://oracle-base.com/">Tim Hall&lt;/a> : Tim is a legend ! I don&amp;rsquo;t consider something a new feature until Tim writes about it :D&lt;/p>
&lt;p>&lt;a href="https://jonathanlewis.wordpress.com/all-postings/">Jonathan Lewis&lt;/a> : I don&amp;rsquo;t think there is anyone on this planet who has even once worked on a performance problem and hasn&amp;rsquo;t gained something from the knowledge shared by him on forums or in one of the blog posts.&lt;/p></description></item></channel></rss>